{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "#from lxml import etree as ET\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_find_text(soup, selector, attrs=None):\n",
    "    finding = soup.find(selector, attrs=attrs)\n",
    "    if finding:\n",
    "        return finding.text\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of function usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCeltic-zaak: vervolging voetbalsupporters voor openlijke geweldpleging na ongeregeldheden voorafgaand aan Ajax-Celtic op 6 november 2013. Openbaar ministerie niet-ontvankelijk verklaard in vervolging Celtic-supporter op de voet van artikel 359a Sv wegens ernstige schending verbaliseringsplicht, die vastgesteld kon worden aan de hand van in een zeer laat stadium aan het dossier toegevoegde camerabeelden. Politie treft verwijt onjuiste verslaglegging ten aanzien van de kern van waar het in deze strafzaak om gaat. De met vervolging belaste ambtenaren treft het verwijt er onvoldoende zorg voor te hebben gedragen dat de door politieambtenaren vervaardigde camerabeelden tijdig aan het dossier konden worden toegevoegd.\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = safe_find_text\n",
    "\n",
    "\n",
    "txt = open('Data 2018-2021/ECLI_NL_GHAMS_2019_194.xml',encoding='utf-8')\n",
    "bs_obj = BeautifulSoup(txt, 'lxml')\n",
    "full_text = bs_obj.text\n",
    "\n",
    "safe_find_text(bs_obj,\"inhoudsindicatie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in of omstreeks de periode van 4 november 2016 tot en met 6 november 2016']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = \"hij in of omstreeks de periode van 4 november 2016 tot en met 6 november 2016 in arnhem en/of in nederland en/of in duitsland en/of in oostenrijk en/of in hongarije, opzettelijk een of meer minderjarige(n)\"\n",
    "crime_date_pattern = 'op of omstreeks [0-9]* [a-z]* [0-9]*|[op]*[in]* of omstreeks de periode van [0-9]* [a-z]*[ 0-9]* tot en met [0-9]* [a-z]* [0-9]*'\n",
    "\n",
    "re.findall(crime_date_pattern, string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Patterns used to extract structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_bewijs = '\\*new_par\\*[0-9]*bewijs[^\\*]*'\n",
    "pattern_tll = '\\*new_par\\*[0-9]*tenlastelegging[^\\*]*'\n",
    "\n",
    "pattern_tll_2 = '[\\s*$]*[0-9]*te[n]*laste[n]*legging[\\s*$]+[\\s*$]+[^\\*]*'\n",
    "pattern_tll_bijlage = '[\\s*$]*[0-9]*bijlage[:]*\\s*[de\\s]*tenlastelegging[\\s*$]+[^\\*]*'\n",
    "tll_pattern_def = '[[\\s*$]*[0-9]*[\\s]*tenlastelegging[\\s*$]+[\\s*$]+[^\\*]*]|[[\\s*$]*[0-9]*bijlage[:]*\\s*[de\\s]*tenlastelegging[\\s*$]+[^\\*]*]'\n",
    "\n",
    "pattern_bewijs_2 = '[\\s*$]+[\\s*$]+[0-9]*bewijs[^\\*]*|[\\s*$]+[\\s*$]+[0-9]*bewijsmiddelen[^\\*]*|[\\s*$]+[\\s*$]+[0-9]*het\\sbewijs[^\\*]*'\n",
    "\n",
    "crime_date_pattern = 'op of omstreeks [0-9]* [a-z]* [0-9]*|[op]*[in]* of omstreeks de periode van [0-9]* [a-z]*[ 0-9]* tot en met [0-9]* [a-z]* [0-9]*'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop to read xml files downloaded from rechtspraak & filter out : documents >1000 characters and subject : strafrecht\n",
    "\n",
    "Note: dcterms: is found in the xml files and we use it to filter for certain values as seen below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = src_folder\n",
    "\n",
    "\n",
    "for filename in os.listdir(path):\n",
    "    if not filename.endswith(\".xml\"): continue\n",
    "    #fullname = os.path.join(path,filename)\n",
    "    source = src_folder + filename\n",
    "    txt = open(source,encoding='utf-8')\n",
    "    bs_obj = BeautifulSoup(txt, 'lxml')\n",
    "    \n",
    "    destination = dst_folder + source\n",
    "    full_text = bs_obj.text\n",
    "    if len(str(full_text)) >= 1000:  #met lengte filter\n",
    "        if \"Strafrecht\" in safe_find_text(bs_obj,\"dcterms:subject\"): #met strafrecht filter\n",
    "            shutil.move(source,destination)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop to open filtered xml files (strafrecht + 1000char), and create dataframe using certain parts of the text containg the regular expression seen above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "tll_list = [] # create empty lists for final dataframe\n",
    "bv_list = []\n",
    "df[\"text\"] = \"\"\n",
    "df[\"is_tll\"] = 0\n",
    "df[\"is_bewijs\"] = \"\"\n",
    "xml_list = [] \n",
    "ecli = []\n",
    "subject = []\n",
    "zaak_nr = []\n",
    "spatial = []\n",
    "procedure = []\n",
    "wb_list= []\n",
    "bijlage_list=[]\n",
    "beslag_list = []\n",
    "tll_2 = []\n",
    "bewijs_2 = []\n",
    "final_tll = []\n",
    "final_bewijs = []\n",
    "counter = 0\n",
    "\n",
    "df_sections = pd.DataFrame()\n",
    "path= \"Dataset\"\n",
    "\n",
    "info_dict = dict()\n",
    "info_list = []\n",
    "\n",
    "cleaned_bewijs = []\n",
    "cleaned_tll = []\n",
    "crime_date = []\n",
    "\n",
    "for filename in os.listdir(path):\n",
    "    if not filename.endswith(\".xml\"): continue\n",
    "    fullname = os.path.join(path,filename)\n",
    "    txt = open(fullname,encoding='utf-8')\n",
    "    bs_obj = BeautifulSoup(txt, 'lxml')\n",
    "    full_text = bs_obj.text\n",
    "    if len(str(full_text)) >= 1000:  #met lengte filter\n",
    "        counter += 1 \n",
    "        xml_list.append(bs_obj) \n",
    "\n",
    "        if \"Strafrecht\" in safe_find_text(bs_obj,\"dcterms:subject\"): #met strafrecht filter\n",
    "            info_dict = dict()\n",
    "            info_dict['filename'] = filename\n",
    "            info_dict['ecli'] = safe_find_text(bs_obj,\"dcterms:identifier\")\n",
    "            info_dict['subject'] = safe_find_text(bs_obj,\"dcterms:subject\")\n",
    "            info_dict['spatial'] = safe_find_text(bs_obj,\"dcterms:spatial\")\n",
    "            info_dict['case_nr'] = safe_find_text(bs_obj,\"psi:zaaknummer\")\n",
    "            info_dict['date'] = safe_find_text(bs_obj, \"dcterms:date\")\n",
    "            info_dict['inhoudsindicatie'] = safe_find_text(bs_obj, \"inhoudsindicatie\")\n",
    "            \n",
    "            #print('_________',filename,'________')\n",
    "            #print(len(str(full_text)))\n",
    "            text = bs_obj.findAll(\"section\")\n",
    "            section_text = [x.text for x in text]\n",
    "            #print(section_text)\n",
    "            for sub_section in section_text: # loop for reading bs object and find patterns\n",
    "                match_tll = re.findall(pattern_tll_2, sub_section.lower())\n",
    "                match_tll_bijlage = re.findall(pattern_tll_bijlage, sub_section.lower())\n",
    "                match_tot = re.findall(tll_pattern_def, sub_section.lower())\n",
    "                if str(match_tot) != '[]':\n",
    "                    tll_2.append(match_tot)\n",
    "    \n",
    "                match_bewijs = re.findall(pattern_bewijs_2, sub_section.lower())\n",
    "                if str(match_bewijs) != []:\n",
    "                    bewijs_2.append(match_bewijs)\n",
    "                    \n",
    "                match_crime_date = re.findall(crime_date_pattern, sub_section.lower())\n",
    "                if match_crime_date not in crime_date:\n",
    "                     if match_crime_date != []:\n",
    "                        crime_date.append(''.join(match_crime_date))\n",
    "            for item_t in tll_2:\n",
    "                #print(item_t)\n",
    "                #print(type(item_t))\n",
    "                #print(repr(item_t))\n",
    "                for inside_t in item_t:\n",
    "                    cleaned_t = inside_t.replace('\\n', ' ')\n",
    "                    cleaned_tll.append(cleaned_t)\n",
    "                    \n",
    "            for item_b in bewijs_2:\n",
    "                for inside_b in item_b:\n",
    "                    cleaned_b = inside_b.replace('\\n', ' ')\n",
    "                    cleaned_bewijs.append(cleaned_b)\n",
    "            \n",
    "            info_dict[\"bewijs\"] = str(cleaned_bewijs)\n",
    "            info_dict[\"tll\"] = str(cleaned_tll)\n",
    "            info_dict[\"crime_date\"] = str(crime_date)\n",
    "            info_list.append(info_dict)\n",
    "            \n",
    "            #print(repr(tll_2))\n",
    "            info_dict= dict()\n",
    "            tll_2 = []\n",
    "            bewijs_2 = []\n",
    "            cleaned_bewijs = []\n",
    "            cleaned_tll = []\n",
    "            crime_date = []\n",
    "            #print('--------------------------------')\n",
    "            #print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(info_list)\n",
    "print(df.shape)\n",
    "#df = df[df['tll'] != '[]']\n",
    "df = df.drop_duplicates(subset = 'filename')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
